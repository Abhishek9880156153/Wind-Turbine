{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04201183-be63-45ea-9534-6c753f8a73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import uvicorn\n",
    "import joblib\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320350f6-f6d1-4516-9c32-84b08b7c64a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create sample dataset and preprocess\n",
    "data = pd.DataFrame({\n",
    "    \"temperature\": np.random.uniform(10, 40, 100),\n",
    "    \"vibration\": np.random.uniform(0.1, 5.0, 100),\n",
    "    \"humidity\": np.random.uniform(30, 90, 100),\n",
    "    \"wind_speed\": np.random.uniform(1, 25, 100)\n",
    "})\n",
    "\n",
    "data.to_csv(\"wind_turbine_data.csv\", index=False)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"wind_turbine_data.csv\")\n",
    "\n",
    "# Selecting relevant features\n",
    "features = [\"temperature\", \"vibration\", \"humidity\", \"wind_speed\"]\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data[features])\n",
    "\n",
    "# Save the scaler for future use\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91cba3c-d11e-4cad-be2e-371be151177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare the dataset for LSTM model\n",
    "sequence_length = 10  # Using past 10 timesteps for prediction\n",
    "X, y = [], []\n",
    "for i in range(len(data_scaled) - sequence_length):\n",
    "    X.append(data_scaled[i : i + sequence_length])\n",
    "    y.append(data_scaled[i + sequence_length][0])  # Predicting temperature as an example\n",
    "X, y = np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f5d4507-f7fb-46d7-9c14-3dec23e572a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Build LSTM Model\n",
    "model = Sequential([\n",
    "    Input(shape=(sequence_length, len(features))),\n",
    "    LSTM(50, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(50, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88889888-d6df-4ab8-b5f1-a34c7d664057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 0.3079 - val_loss: 0.3149\n",
      "Epoch 2/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2489 - val_loss: 0.2473\n",
      "Epoch 3/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1821 - val_loss: 0.1815\n",
      "Epoch 4/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1511 - val_loss: 0.1247\n",
      "Epoch 5/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1089 - val_loss: 0.1028\n",
      "Epoch 6/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1196 - val_loss: 0.1063\n",
      "Epoch 7/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1387 - val_loss: 0.1026\n",
      "Epoch 8/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.1114 - val_loss: 0.1043\n",
      "Epoch 9/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1078 - val_loss: 0.1096\n",
      "Epoch 10/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1038 - val_loss: 0.1104\n",
      "Epoch 11/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1097 - val_loss: 0.1080\n",
      "Epoch 12/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1052 - val_loss: 0.1048\n",
      "Epoch 13/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1031 - val_loss: 0.1045\n",
      "Epoch 14/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1044 - val_loss: 0.1056\n",
      "Epoch 15/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0897 - val_loss: 0.1058\n",
      "Epoch 16/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.1032 - val_loss: 0.1031\n",
      "Epoch 17/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0950 - val_loss: 0.1003\n",
      "Epoch 18/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0966 - val_loss: 0.0992\n",
      "Epoch 19/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0997 - val_loss: 0.0991\n",
      "Epoch 20/20\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.1010 - val_loss: 0.0995\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Train the Model\n",
    "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Save the trained model using the recommended format\n",
    "model.save(\"lstm_wind_turbine.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9057c-7d06-4476-8973-0f630e756236",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [2004]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 611ms/step\n",
      "INFO:     127.0.0.1:63513 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Deploying the Model with FastAPI\n",
    "app = FastAPI()\n",
    "\n",
    "# Load the trained model and scaler\n",
    "model = tf.keras.models.load_model(\"lstm_wind_turbine.keras\", compile=False)\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    data: list\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(input_data: InputData):\n",
    "    try:\n",
    "        input_array = np.array(input_data.data).reshape(1, sequence_length, len(features))\n",
    "        prediction = model.predict(input_array)\n",
    "        return {\"predicted_temperature\": float(prediction[0][0])}\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8001)  # Change port from 8000 to 8001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0170a5-6cf8-40f1-8e31-272e5cb13883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
